{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d834719",
   "metadata": {},
   "source": [
    "## Example usage of `adversarial_gym` wrappers using OpenAI Gym and `stable-baselines3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8e805d",
   "metadata": {},
   "source": [
    "Import required packages.\n",
    "\n",
    "`gym` is needed for RL environments.\n",
    "We use PPO from stable-baselines.\n",
    "\n",
    "`adversarial_gym` contains 3 wrappers at the moment. One each for adding nosie to observations, actions, and reward. Each of these wrappers is imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fddb4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gym\n",
    "from adversarial_gym.wrappers import ObsNoiseWrapper, ActionNoiseWrapper, RewardNoiseWrapper\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d56d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0fb0fb",
   "metadata": {},
   "source": [
    "Create the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef19af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"ContinuousCartPole-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbe8451",
   "metadata": {},
   "source": [
    "Let's try training a PPO agent on this version of the environment without noise so we can see what impact, if any, the noise we add to the next version of the environment will have on performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21357e06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobpettit/Documents/git/adversarial-gym/adversarial_gym/envs/cartpole.py:131: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(self.state), reward, done, {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.9     |\n",
      "|    ep_rew_mean     | 24.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 2537     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.5         |\n",
      "|    ep_rew_mean          | 28.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1653         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062948144 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.000331     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.04         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00903     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 56.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 36.4        |\n",
      "|    ep_rew_mean          | 36.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1526        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009028685 |\n",
      "|    clip_fraction        | 0.0858      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.0847      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 47.1         |\n",
      "|    ep_rew_mean          | 47.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1433         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105736945 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.366        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0186      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 48.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.8        |\n",
      "|    ep_rew_mean          | 60.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1389        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006786146 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 62          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7ffbd002aa00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1502461",
   "metadata": {},
   "source": [
    "Wrap the environment in an observation noise wrapper. This wrapper will sample noise from a normal distribution with a mean of zero and a standard deviation of 1.\n",
    "\n",
    "These parameters can be changed to make the noise more challenging, for example you can change the mean (which will immediately make the environment much more challenging compared to a 0 mean) or increase the standard deviation so there is greater spread to the noise.\n",
    "\n",
    "You can also try a different noise type. The available options are:\n",
    "- `\"normal\"`\n",
    "- `\"uniform\"`\n",
    "- `\"discrete_uniform\"`\n",
    "- `\"beta\"`\n",
    "- `\"poisson\"`\n",
    "\n",
    "Each distribution has the same keyword arguments as the NumPy functions of the same signature (e.g `\"normal\"` has the same arguments as `numpy.random.normal` and so on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13f3767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ObsNoiseWrapper(env, \"normal\", dict(loc=0, scale=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7806753d",
   "metadata": {},
   "source": [
    "Now, we can use stable-baselines to train on the environment for 10000 timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a44f143",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.2     |\n",
      "|    ep_rew_mean     | 25.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 2354     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 24.7         |\n",
      "|    ep_rew_mean          | 24.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026303488 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -0.00678     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 69.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 25.5         |\n",
      "|    ep_rew_mean          | 25.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1408         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045410097 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.00492      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 29.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1345        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004197565 |\n",
      "|    clip_fraction        | 0.0454      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.0259      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    std                  | 0.956       |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | 31.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034541553 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.00636      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.8         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    std                  | 0.938        |\n",
      "|    value_loss           | 58.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7ffbd66d75b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bb0b08",
   "metadata": {},
   "source": [
    "Even though we only ran for 10,000 timesteps, which is not enough to train a model to convergence, we can already see the impact that the added noise is having on the training process. The model trained on the environment *without* noise has already obtained a reward of 65.5 at timestep 10240, while the model trained on the *noisy* environment only has a reward of 33.8.\n",
    "\n",
    "The `ActionNoiseWrapper` and `RewardNoiseWrapper` work in the same way as the `ObsNoiseWrapper`demoed here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
